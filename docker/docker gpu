 配置 Docker 使用 GPU
准备工作

首先你需要准备一台拥有GPU的实例，在这里我将使用阿里云的竞价实例来做演示，因为它对于短期使用GPU更加划算。

    注意，本篇文章将教你手动进行GPU驱动的配置，所以在购买时选择系统的时候不要选择自动安装GPU驱动。

具体关于竞价实例如何购买和配置，请参考各个云平台的介绍，本文不再赘述。
主机配置

在这里我买了一台配有Ubuntu 22.04和一块T4显卡的实例作为演示。
显卡驱动安装

    现在我们需要安装 NVIDIA 的驱动，在这里下载驱动。
    选择你的显卡和CUDA Toolkit版本，以及你的系统版本，就能得到相应的驱动下载。
    在这个案例中我的显卡选择的是 Tesla T4 ，系统选择 Linux64-bit，CUDA Toolkit 选择 12.0。
    点击搜索后就能得到对应的驱动，点击下载后就得到了对应的驱动。
    把驱动文件上传到你的实例上，并用以下命令进行安装：

$chmod 755 NVIDIA-Linux-x86_64-525.85.12.run
$sudo ./NVIDIA-Linux-x86_64-525.85.12.run --no-cc-version-check

    脚本中的版本号可能会随有所变化，请以你下载的驱动为准。

安装完后执行 nvidia-smi 命令显示如下就是安装完成了：

Fri Mar  3 15:17:34 2023
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |
| N/A   57C    P0    30W /  70W |      2MiB / 15360MiB |      7%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Docker 安装

可以使用 Docker 的官方脚本在 Ubuntu 上设置 Docker-CE：

curl https://get.docker.com | sh \
  && sudo systemctl --now enable docker

    请按照官方说明了解更多详细信息和安装后操作。

安装 NVIDIA Container Toolkit
在线安装

设置软件包仓库和GPG密钥

$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

在更新软件包列表之后，安装 nvidia-container-toolkit 包（以及依赖项）。

$ sudo apt-get update

$ sudo apt-get install -y nvidia-container-toolkit

离线安装

离线安装包都在以下仓库和分支下：
https://github.com/NVIDIA/libnvidia-container/tree/gh-pages

以 ubuntu22.04为例，点开对应的目录，如果显示的是 Symbolic Link，则表示是个软链，例如我这点开后是 stable/ubuntu22.04，则代表软链到这个目录，进行跳转后发现还是一个 Symbolic Link ，里面是 ubuntu18.04，继续跳转，现在出现了系统的选择，这里我选择 amd64，进去后的目录里就是对应的安装包了。

在这里我们需要选择如下的安装包：

nvidia-container-toolkit-base_xxxx-1_amd64
nvidia-container-toolkit_1.xxxx-1_amd64
libnvidia-container1_1.xxxx-1_amd64
libnvidia-container-tools_1.xxxx-1_amd64

xxxx代表对应的 CUDA 版本，在我的这个实例中 xxxx，就是12.0，按以下顺序安装：

 dpkg -i libnvidia-container1_1.12.0-1_amd64.deb 
 dpkg -i libnvidia-container-tools_1.12.0-1_amd64.deb
 dpkg -i nvidia-container-toolkit-base_1.12.0-1_amd64.deb
 dpkg -i nvidia-container-toolkit_1.12.0-1_amd64.deb

配置Docker守护程序，使其能够识别NVIDIA Container Runtime：

$ sudo nvidia-ctk runtime configure --runtime=docker

在设置默认 runtime 后，重新启动Docker守护程序以完成安装。

$ sudo systemctl restart docker

测试

最后，通过运行一个基本的CUDA容器来测试是否配置完成：

$ sudo docker run --rm --runtime=nvidia --gpus all  nvidia/cuda:12.0.1-runtime-ubuntu22.04 nvidia-smi

输出如下所示就代表你的容器以及支持GPU：

Fri Mar  3 07:47:04 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |
| N/A   37C    P0    27W /  70W |      2MiB / 15360MiB |      7%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

,
  "default-runtime": "nvidia",
  "experimental": false,
  "runtimes": {
    "nvidia": {
      "path": "nvidia-container-runtime",
      "runtimeArgs": []
    }
  }