# Opencv Stitching源码分析（四）
>参考 zhaocj [Opencv2.4.9源码分析——Stitching（四）](https://blog.csdn.net/zhaocj/article/details/78829736)
## 1. 原理

<!--  有时间再写  -->


---

## 2. 源码
RotationWarper类是只处理因旋转而引起的图像扭曲的接口类，它是RotationWarperBase类的基类：

``` c++
class CV_EXPORTS RotationWarper
{
public:
    virtual ~RotationWarper() {}

    /** @brief Projects the image point.

    @param pt Source point
    @param K Camera intrinsic parameters
    @param R Camera rotation matrix
    @return Projected point
     */
    virtual Point2f warpPoint(const Point2f &pt, InputArray K, InputArray R) = 0;

    /** @brief Builds the projection maps according to the given camera data.

    @param src_size Source image size
    @param K Camera intrinsic parameters
    @param R Camera rotation matrix
    @param xmap Projection map for the x axis
    @param ymap Projection map for the y axis
    @return Projected image minimum bounding box
     */
    virtual Rect buildMaps(Size src_size, InputArray K, InputArray R, OutputArray xmap, OutputArray ymap) = 0;

    /** @brief Projects the image.

    @param src Source image
    @param K Camera intrinsic parameters
    @param R Camera rotation matrix
    @param interp_mode Interpolation mode
    @param border_mode Border extrapolation mode
    @param dst Projected image
    @return Project image top-left corner
     */
    virtual Point warp(InputArray src, InputArray K, InputArray R, int interp_mode, int border_mode,
                       OutputArray dst) = 0;

    /** @brief Projects the image backward.

    @param src Projected image
    @param K Camera intrinsic parameters
    @param R Camera rotation matrix
    @param interp_mode Interpolation mode
    @param border_mode Border extrapolation mode
    @param dst_size Backward-projected image size
    @param dst Backward-projected image
     */
    virtual void warpBackward(InputArray src, InputArray K, InputArray R, int interp_mode, int border_mode,
                              Size dst_size, OutputArray dst) = 0;

    /**
    @param src_size Source image bounding box
    @param K Camera intrinsic parameters
    @param R Camera rotation matrix
    @return Projected image minimum bounding box
     */
    virtual Rect warpRoi(Size src_size, InputArray K, InputArray R) = 0;

    //这里给出了默认scale为1.f
    virtual float getScale() const { return 1.f; }
    virtual void setScale(float) {}
};
```
RotationWarperBase类继承自RotationWarper，它规定了其实例运用的投影方法projector_，projector_在buildMaps方法中负责正向和反向投影
``` C++
template <class P>
class CV_EXPORTS RotationWarperBase : public RotationWarper
{
public:
    //表示投影图像的像素点，pt为源像素点，它通过P.mapForward函数得到投影点（该函数的返回值），K为相机的内参数，R为相机的旋转矩阵，通过P.setCameraParams函数设置
    Point2f warpPoint(const Point2f &pt, const Mat &K, const Mat &R);
    //由给定的相机数据建立投影关系，src_size为源图像区域，xmap和ymap是分别表示坐标值由两次映射的值，该函数返回投影图区域
    Rect buildMaps(Size src_size, const Mat &K, const Mat &R, Mat &xmap, Mat &ymap);
    //表示由源图src经buildMaps函数得到投影图像dst，interp_mode和border_mode分别表示投影时用到的插值算法和边界扩展方法，该函数返回dst在最终的全景图像投影后的左上角坐标
    Point warp(const Mat &src, const Mat &K, const Mat &R, int interp_mode, int border_mode,
               Mat &dst);
    //与buildMaps函数相类似，只不过该函数使用的是P.mapForward函数
    void warpBackward(const Mat &src, const Mat &K, const Mat &R, int interp_mode, int border_mode,
                      Size dst_size, Mat &dst);
    //表示确定扭曲图像区域
    Rect warpRoi(Size src_size, const Mat &K, const Mat &R);
 
    float getScale() const { return projector_.scale; }    //得到尺度
    void setScale(float val) { projector_.scale = val; }    //设置尺度
 
protected:
 
    // Detects ROI of the destination image. It's correct for any projection.
    //该虚函数用于得到目标图像的区域
    virtual void detectResultRoi(Size src_size, Point &dst_tl, Point &dst_br);
 
    // Detects ROI of the destination image by walking over image border.
    // Correctness for any projection isn't guaranteed.
    //该函数仅由源图像的边界得到目标图像的区域
    void detectResultRoiByBorder(Size src_size, Point &dst_tl, Point &dst_br);
 
    P projector_;    //表示投影的方法
};
```

下面我们给出RotationWarperBase类中主要函数的介绍：

``` c++
template <class P>
Point2f RotationWarperBase<P>::warpPoint(const Point2f &pt, const Mat &K, const Mat &R)
//pt表示投射的源点
//K表示相机的内参数
//R表示相机的旋转参数
//该函数返回投射点
{
    projector_.setCameraParams(K, R);    //设置相机参数
    Point2f uv;    //表示投射映射点
    projector_.mapForward(pt.x, pt.y, uv.x, uv.y);    //前向投影，得到投射点
    return uv;    //返回投射点
}
```

``` c++
template <class P>
Rect RotationWarperBase<P>::buildMaps(Size src_size, const Mat &K, const Mat &R, Mat &xmap, Mat &ymap)
//src_size表示源图的区域
//K表示相机的内参数
//R表示相机的旋转参数
//xmap和ymap分别表示返回横纵坐标的前向映射后再反向映射的值
//该函数返回投影后的区域尺寸
{
    projector_.setCameraParams(K, R);    //设置相机参数
 
    Point dst_tl, dst_br;    //表示投影区域的左上角坐标和右下角坐标
    //得到映射后的左上角坐标dst_tl和右下角坐标dst_br
    detectResultRoi(src_size, dst_tl, dst_br); 
    //创建xmap和ymap矩阵大小
    xmap.create(dst_br.y - dst_tl.y + 1, dst_br.x - dst_tl.x + 1, CV_32F);
    ymap.create(dst_br.y - dst_tl.y + 1, dst_br.x - dst_tl.x + 1, CV_32F);
 
    float x, y;    //表示反向投影映射后的x轴和y轴坐标值
    //遍历投影区域，再进行反向映射
    for (int v = dst_tl.y; v <= dst_br.y; ++v) 
    {
        for (int u = dst_tl.x; u <= dst_br.x; ++u)
        {
            //反向投影
            projector_.mapBackward(static_cast<float>(u), static_cast<float>(v), x, y);
            xmap.at<float>(v - dst_tl.y, u - dst_tl.x) = x;    //赋值
            ymap.at<float>(v - dst_tl.y, u - dst_tl.x) = y;    //赋值
        }
    }
 
    return Rect(dst_tl, dst_br);    //返回投影映射区域
}
```

``` c++
template <class P>
Point RotationWarperBase<P>::warp(const Mat &src, const Mat &K, const Mat &R, int interp_mode, int border_mode,
                                  Mat &dst)
//src表示源图
//K表示相机内参数
//R表示相机的旋转参数
//interp_mode表示插值模式
//border_mode表示边界扩充模式
//dst表示投影映射图
//该函数返回投影映射图的左上角在基准图像坐标系下的坐标，即全景图像坐标系下的坐标
{
    Mat xmap, ymap;
    Rect dst_roi = buildMaps(src.size(), K, R, xmap, ymap);    //调用buildMaps函数
 
    dst.create(dst_roi.height + 1, dst_roi.width + 1, src.type());    //创建大小
    //按xmap和ymap对src进行重映射，得到dst
    remap(src, dst, xmap, ymap, interp_mode, border_mode);
 
    return dst_roi.tl();    //返回左上角坐标
}
```

``` c++
template <class P>
Rect RotationWarperBase<P>::warpRoi(Size src_size, const Mat &K, const Mat &R)
//src表示源图
//K表示相机内参数
//R表示相机的旋转参数
//返回投影矩形区域
{
    projector_.setCameraParams(K, R);    //设置相机参数
 
    Point dst_tl, dst_br;
    detectResultRoi(src_size, dst_tl, dst_br);    //得到映射区域
 
    return Rect(dst_tl, Point(dst_br.x + 1, dst_br.y + 1));    //返回映射矩形区域
}
```

``` c++
template <class P>
void RotationWarperBase<P>::detectResultRoi(Size src_size, Point &dst_tl, Point &dst_br)
//src_size表示源图像区域
//dst_tl和dst_br分别表示返回得到的投影后区域的左上角坐标和右下角坐标
{
    //下面4个变量分别表示左上角和右下角x轴和y轴的值
    float tl_uf = std::numeric_limits<float>::max();    //先初始化为最大值
    float tl_vf = std::numeric_limits<float>::max();    //先初始化为最大值
    float br_uf = -std::numeric_limits<float>::max();    //先初始化为最小值
    float br_vf = -std::numeric_limits<float>::max();    //先初始化为最小值
 
    float u, v;
    for (int y = 0; y < src_size.height; ++y)    //遍历源图区域
    {
        for (int x = 0; x < src_size.width; ++x)
        {
            //前向映射
            projector_.mapForward(static_cast<float>(x), static_cast<float>(y), u, v);
            tl_uf = std::min(tl_uf, u); tl_vf = std::min(tl_vf, v);    //更新左上角坐标
            br_uf = std::max(br_uf, u); br_vf = std::max(br_vf, v);    //更新右下角坐标
        }
    }
    //得到最终的左上角和右下角坐标
    dst_tl.x = static_cast<int>(tl_uf);
    dst_tl.y = static_cast<int>(tl_vf);
    dst_br.x = static_cast<int>(br_uf);
    dst_br.y = static_cast<int>(br_vf);
}
```

``` c++
template <class P>
void RotationWarperBase<P>::detectResultRoiByBorder(Size src_size, Point &dst_tl, Point &dst_br)
{
    //下面4个变量分别表示左上角和右下角x轴和y轴的值
    float tl_uf = std::numeric_limits<float>::max();    //先初始化为最大值
    float tl_vf = std::numeric_limits<float>::max();    //先初始化为最大值
    float br_uf = -std::numeric_limits<float>::max();    //先初始化为最小值
    float br_vf = -std::numeric_limits<float>::max();    //先初始化为最小值
 
    float u, v;
    for (float x = 0; x < src_size.width; ++x)    //遍历源图的横坐标
    {
        projector_.mapForward(static_cast<float>(x), 0, u, v);    //上边映射
        tl_uf = std::min(tl_uf, u); tl_vf = std::min(tl_vf, v);
        br_uf = std::max(br_uf, u); br_vf = std::max(br_vf, v);
        //下边映射
        projector_.mapForward(static_cast<float>(x), static_cast<float>(src_size.height - 1), u, v);
        tl_uf = std::min(tl_uf, u); tl_vf = std::min(tl_vf, v);
        br_uf = std::max(br_uf, u); br_vf = std::max(br_vf, v);
    }
    for (int y = 0; y < src_size.height; ++y)    //遍历源图的纵坐标
    {
        projector_.mapForward(0, static_cast<float>(y), u, v);    左边映射
        tl_uf = std::min(tl_uf, u); tl_vf = std::min(tl_vf, v);
        br_uf = std::max(br_uf, u); br_vf = std::max(br_vf, v);
        //右边映射
        projector_.mapForward(static_cast<float>(src_size.width - 1), static_cast<float>(y), u, v);
        tl_uf = std::min(tl_uf, u); tl_vf = std::min(tl_vf, v);
        br_uf = std::max(br_uf, u); br_vf = std::max(br_vf, v);
    }
    //得到坐标
    dst_tl.x = static_cast<int>(tl_uf);
    dst_tl.y = static_cast<int>(tl_vf);
    dst_br.x = static_cast<int>(br_uf);
    dst_br.y = static_cast<int>(br_vf);
}
```
SphericalWarper类继承自RotationWarperBase类，规定了其投影方法为SphericalProjector。该类重写了buildMaps和detectResultRoi方法，以支持OPENCL加速。如果没有配置OPENCL，则仍调用父类的方法。
``` c++
/** @brief Warper that maps an image onto the unit sphere located at the origin.

 Projects image onto unit sphere with origin at (0, 0, 0) and radius scale, measured in pixels.
 A 360 panorama would therefore have a resulting width of 2 * scale * PI pixels.
 Poles are located at (0, -1, 0) and (0, 1, 0) points.
*/
class CV_EXPORTS SphericalWarper : public RotationWarperBase<SphericalProjector>
{
public:
    /** @brief Construct an instance of the spherical warper class.

    @param scale Radius of the projected sphere, in pixels. An image spanning the
                 whole sphere will have a width of 2 * scale * PI pixels.
     */
    SphericalWarper(float scale) { projector_.scale = scale; }

    Rect buildMaps(Size src_size, InputArray K, InputArray R, OutputArray xmap, OutputArray ymap) CV_OVERRIDE;
    Point warp(InputArray src, InputArray K, InputArray R, int interp_mode, int border_mode, OutputArray dst) CV_OVERRIDE;
protected:
    void detectResultRoi(Size src_size, Point &dst_tl, Point &dst_br) CV_OVERRIDE;
};
```

投影方法的基类结构为：

``` c++
struct CV_EXPORTS ProjectorBase
{
    //设置相机参数，该函数见后面的介绍
    void setCameraParams(const Mat &K = Mat::eye(3, 3, CV_32F),
                         const Mat &R = Mat::eye(3, 3, CV_32F),
                         const Mat &T = Mat::zeros(3, 1, CV_32F));
 
    float scale;    //表示尺度
    float k[9];    //表示相机的内参数矩阵K，用向量形式表示
    //在前面的程序分析中，我们已强调过，程序中所表示的旋转矩阵r其实是公式中旋转矩阵R的逆
    float rinv[9];    //表示相机旋转矩阵r的逆（就是R），用向量形式表示
    float r_kinv[9];    //表示rK-1（就是R-1K-1），用向量形式表示
    float k_rinv[9];    //表示Kr-1（就是KR），用向量形式表示
    float t[3];    //表示三个方向的平移量
};
```

设置相机的内外参数：
``` c++
void ProjectorBase::setCameraParams(const Mat &K, const Mat &R, const Mat &T)
//K表示相机的内参数
//R表示相机的旋转参数
//T表示相机的平移量
{
    //确保三个输入参数正确
    CV_Assert(K.size() == Size(3, 3) && K.type() == CV_32F);
    CV_Assert(R.size() == Size(3, 3) && R.type() == CV_32F);
    CV_Assert((T.size() == Size(1, 3) || T.size() == Size(3, 1)) && T.type() == CV_32F);
 
    Mat_<float> K_(K);    //复制
    //把矩阵形式的K转换为向量形式的k
    k[0] = K_(0,0); k[1] = K_(0,1); k[2] = K_(0,2);
    k[3] = K_(1,0); k[4] = K_(1,1); k[5] = K_(1,2);
    k[6] = K_(2,0); k[7] = K_(2,1); k[8] = K_(2,2);
 
    Mat_<float> Rinv = R.t();    //得到r的逆，即R-1
    //得到向量形式的rinv
    rinv[0] = Rinv(0,0); rinv[1] = Rinv(0,1); rinv[2] = Rinv(0,2);
    rinv[3] = Rinv(1,0); rinv[4] = Rinv(1,1); rinv[5] = Rinv(1,2);
    rinv[6] = Rinv(2,0); rinv[7] = Rinv(2,1); rinv[8] = Rinv(2,2);
 
    Mat_<float> R_Kinv = R * K.inv();    //得到rK-1，即R-1K-1
    //得到向量形式的r_kinv
    r_kinv[0] = R_Kinv(0,0); r_kinv[1] = R_Kinv(0,1); r_kinv[2] = R_Kinv(0,2);
    r_kinv[3] = R_Kinv(1,0); r_kinv[4] = R_Kinv(1,1); r_kinv[5] = R_Kinv(1,2);
    r_kinv[6] = R_Kinv(2,0); r_kinv[7] = R_Kinv(2,1); r_kinv[8] = R_Kinv(2,2);
 
    Mat_<float> K_Rinv = K * Rinv;    //得到Kr-1，即KR
    //得到向量形式的k_rinv
    k_rinv[0] = K_Rinv(0,0); k_rinv[1] = K_Rinv(0,1); k_rinv[2] = K_Rinv(0,2);
    k_rinv[3] = K_Rinv(1,0); k_rinv[4] = K_Rinv(1,1); k_rinv[5] = K_Rinv(1,2);
    k_rinv[6] = K_Rinv(2,0); k_rinv[7] = K_Rinv(2,1); k_rinv[8] = K_Rinv(2,2);
 
    Mat_<float> T_(T.reshape(0, 3));    //复制
    //把矩阵形式的T转换为向量形式的t
    t[0] = T_(0,0); t[1] = T_(1,0); t[2] = T_(2,0);
}
```

各种扭曲方法都是以RotationWarperBase为基类，各种投影方法都是以ProjectorBase为基类，扭曲和投影是一一对应的，通过不同的投影算法实现不同的图像扭曲。Opencv实现了许多投影算法，有平面、柱面、球面、鱼眼、立方体、压缩直线、压缩直线人像、panini（弯曲）、panini人像、Mercator（正轴等角柱面）、横向Mercator、球面人像、柱面人像、平面人像等投影算法。只要投影算法掌握了，通过映射得到图像扭曲就很容易。


球面投影：
``` c++
inline
void SphericalProjector::mapForward(float x, float y, float &u, float &v)    //正向
{
    //式70
    float x_ = r_kinv[0] * x + r_kinv[1] * y + r_kinv[2];
    float y_ = r_kinv[3] * x + r_kinv[4] * y + r_kinv[5];
    float z_ = r_kinv[6] * x + r_kinv[7] * y + r_kinv[8];
    //式77
    u = scale * atan2f(x_, z_);
    float w = y_ / sqrtf(x_ * x_ + y_ * y_ + z_ * z_);
    v = scale * (static_cast<float>(CV_PI) - acosf(w == w ? w : 0));
}
```

``` c++
inline
void SphericalProjector::mapBackward(float u, float v, float &x, float &y)    //反向
{
    u /= scale;
    v /= scale;
    //式78
    float sinv = sinf(static_cast<float>(CV_PI) - v);
    float x_ = sinv * sinf(u);
    float y_ = cosf(static_cast<float>(CV_PI) - v);
    float z_ = sinv * cosf(u);
 
    float z;
    x = k_rinv[0] * x_ + k_rinv[1] * y_ + k_rinv[2] * z_;
    y = k_rinv[3] * x_ + k_rinv[4] * y_ + k_rinv[5] * z_;
    z = k_rinv[6] * x_ + k_rinv[7] * y_ + k_rinv[8] * z_;
    //式74
    if (z > 0) { x /= z; y /= z; }
    else x = y = -1;
}
```